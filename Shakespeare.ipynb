{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load In Some Plays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading A Midsummer-Night's Dream.txt\n",
      "reading All's Well that Ends Well.txt\n",
      "reading As You Like It.txt\n",
      "reading Cymbeline.txt\n",
      "reading Love's Labour's Lost.txt\n",
      "reading Measure for Measure.txt\n",
      "reading Much Ado About Nothing.txt\n",
      "reading Pericles, Prince of Tyre.txt\n",
      "reading The Comedy of Errors.txt\n",
      "reading The Merchant Of Venice.txt\n",
      "reading The Merry Wives of Windsor.txt\n",
      "reading The Taming of the Shrew.txt\n",
      "reading The Tempest.txt\n",
      "reading The Two Gentlemen of Verona.txt\n",
      "reading The Winter's Tale.txt\n",
      "reading Troilus and Cressida.txt\n",
      "reading Twelfth-Night; or What You Will.txt\n",
      "reading The Famous History of the Life of King Henry VIII.txt\n",
      "reading The First Part of King Henry IV.txt\n",
      "reading The First Part of King Henry VI.txt\n",
      "reading The Life and Death of King John.txt\n",
      "reading The Life of King Henry V.txt\n",
      "reading The Second Part of King Henry IV.txt\n",
      "reading The Second Part of King Henry VI.txt\n",
      "reading The Third Part of King Henry VI.txt\n",
      "reading The Tragedy of King Richard II.txt\n",
      "reading The Tragedy of King Richard III.txt\n",
      "reading Anthony and Cleopatra.txt\n",
      "reading Coriolanus.txt\n",
      "reading Hamlet, Prince of Denmark.txt\n",
      "reading Julius Caesar.txt\n",
      "reading King Lear.txt\n",
      "reading Macbeth.txt\n",
      "reading Othello, the Moor of Venice.txt\n",
      "reading Romeo And Juliet.txt\n",
      "reading Timon of Athens.txt\n",
      "reading Titus Andronicus.txt\n"
     ]
    }
   ],
   "source": [
    "base = \"./TXT\"\n",
    "tokens = []\n",
    "\n",
    "replacer = re.compile(r\"[^A-z \\t\\n,.:;'?!]\")\n",
    "\n",
    "for genre in os.listdir(base):\n",
    "    genre_path = os.path.join(base, genre)\n",
    "    for handle in os.listdir(genre_path):\n",
    "        if handle.endswith(\".txt\"):\n",
    "            play = os.path.join(genre_path, handle)\n",
    "            print \"reading {p}\".format(p=handle)\n",
    "            with open(play, \"r\") as f:\n",
    "                for line in f.readlines():\n",
    "                    line = replacer.sub(\"\", line)\n",
    "                    if line.startswith(\"\\t\"):\n",
    "                        for token in line[1:]:\n",
    "                            tokens.append(token.upper())\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4252756\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "print len(tokens)\n",
    "print len(set(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOW, FAIR HIPPOLYTA, OUR NUPTIAL HOUR\n",
      "DRAWS ON APACE: FOUR HAPPY DAYS BRING IN\n",
      "ANOTHER MOON; BUT O! METHINKS HOW SLOW\n",
      "THIS OLD MOON WANES; SHE LINGERS MY DESIRES,\n",
      "LIKE TO A STEP DAME, OR A DOWAGER\n",
      "LONG WITHERING OUT A YOUNG MAN'S REVENUE.\n",
      "FOUR DAYS WILL QUICKLY STEEP THEMSELVES IN NIGHT;\n",
      "FOUR NIGHTS\n"
     ]
    }
   ],
   "source": [
    "print \"\".join(tokens[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_unique_tokens = len(set(tokens))\n",
    "token_to_index = dict((b, a) for a, b in enumerate(list(set(tokens))))\n",
    "index_to_token = dict((b, a) for a, b in token_to_index.iteritems())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def TokenToInput(tok):\n",
    "    idx = token_to_index[tok]\n",
    "    arr = np.zeros(num_unique_tokens)\n",
    "    arr[idx] = 1\n",
    "    return arr\n",
    "\n",
    "def ArrayToToken(arr):\n",
    "    idx = arr.argmax()\n",
    "    return index_to_token[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4252756, 37)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = np.array([TokenToInput(tok) for tok in tokens])\n",
    "corpus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOW, FAIR HIPPOLYTA, OUR NUPTIAL HOUR\n",
      "DRAWS ON APACE: FOUR HAPPY DAYS BRING IN\n",
      "ANOTHER MOON; BUT O! METHINKS HOW SLOW\n",
      "THIS OLD MOON WANES; SHE LINGERS MY DESIRES,\n",
      "LIKE TO A STEP DAME, OR A DOWAGER\n",
      "LONG WITHERING OUT A YOUNG MAN'S REVENUE.\n",
      "FOUR DAYS WILL QUICKLY STEEP THEMSELVES IN NIGHT;\n",
      "FOUR NIGHTS\n"
     ]
    }
   ],
   "source": [
    "print \"\".join([ArrayToToken(arr) for arr in corpus[:300]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Tensorflow Models to Predict the Next Character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.models.rnn import rnn_cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Softmax Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0.168\n",
      "0 1 0.168\n",
      "0 2 0.168\n",
      "0 3 0.168\n",
      "0 4 0.168\n",
      "0 5 0.168\n",
      "0 6 0.199\n",
      "0 7 0.199\n",
      "0 8 0.199\n",
      "0 9 0.199\n",
      "0 10 0.199\n",
      "0 11 0.199\n",
      "0 12 0.199\n",
      "0 13 0.199\n"
     ]
    }
   ],
   "source": [
    "batch_size = 300000\n",
    "learning_rate = 0.00002\n",
    "num_epochs = 1\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Define the computation graph\n",
    "    inputs = tf.placeholder(tf.float32, [None, num_unique_tokens])\n",
    "    W = tf.Variable(tf.zeros([num_unique_tokens, num_unique_tokens]))\n",
    "    b = tf.Variable(tf.zeros([num_unique_tokens]))\n",
    "    outputs = tf.nn.softmax(tf.matmul(inputs, W) + b)\n",
    "    targets = tf.placeholder(tf.float32, [None, num_unique_tokens])\n",
    "    xentropy = -tf.reduce_sum(targets * tf.log(outputs))\n",
    "    \n",
    "    # Initialization\n",
    "    init = tf.initialize_all_variables()\n",
    "    sess.run(init)\n",
    "    \n",
    "    # Training\n",
    "    train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(xentropy)\n",
    "    for epoch in xrange(num_epochs):\n",
    "        i = 0\n",
    "        move_to_next_epoch = False\n",
    "        while not move_to_next_epoch:\n",
    "            try:\n",
    "                batch_inputs = corpus[i * batch_size:(i + 1) * batch_size]\n",
    "                batch_targets = corpus[(i * batch_size) + 1:((i + 1) * batch_size) + 1]\n",
    "                sess.run(train_step, feed_dict={inputs: batch_inputs, targets: batch_targets})\n",
    "                correct = tf.equal(tf.argmax(outputs, 1), tf.argmax(targets, 1))\n",
    "                accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "                print epoch, i, sess.run(\n",
    "                    accuracy, feed_dict={inputs: corpus[-1001:-1], targets: corpus[-1000:]})\n",
    "                i += 1\n",
    "            except Exception as e:\n",
    "                if type(e) == KeyboardInterrupt:\n",
    "                    raise(e)\n",
    "                move_to_next_epoch = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalize to N-Gram Softmax With a Totally Unnecessary And Harmful Compression Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0.168\n",
      "0 1 0.168\n",
      "0 2 0.168\n",
      "0 3 0.168\n",
      "0 4 0.168\n",
      "0 5 0.168\n",
      "0 6 0.168\n",
      "0 7 0.168\n",
      "0 8 0.168\n",
      "0 9 0.168\n",
      "0 10 0.168\n",
      "0 11 0.168\n",
      "0 12 0.168\n",
      "0 13 0.168\n",
      "0 14 0.168\n",
      "0 15 0.168\n",
      "0 16 0.168\n",
      "0 17 0.168\n",
      "0 18 0.168\n",
      "0 19 0.168\n",
      "0 20 0.168\n",
      "0 21 0.168\n",
      "0 22 0.168\n",
      "0 23 0.168\n",
      "0 24 0.168\n",
      "0 25 0.168\n",
      "0 26 0.168\n",
      "0 27 0.168\n",
      "0 28 0.168\n",
      "0 29 0.168\n",
      "0 30 0.168\n",
      "0 31 0.168\n",
      "0 32 0.168\n",
      "0 33 0.168\n",
      "0 34 0.168\n",
      "0 35 0.168\n",
      "0 36 0.168\n",
      "0 37 0.168\n",
      "0 38 0.168\n",
      "0 39 0.168\n",
      "0 40 0.168\n",
      "0 41 0.168\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100000\n",
    "learning_rate = 0.00001\n",
    "grams = 5\n",
    "hidden_layer_size = num_unique_tokens / 2\n",
    "num_epochs = 1\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Define the computation graph\n",
    "    inputs = tf.placeholder(tf.float32, [None, grams * num_unique_tokens])\n",
    "    W0 = tf.Variable(tf.zeros([grams * num_unique_tokens, hidden_layer_size]))\n",
    "    b0 = tf.Variable(tf.zeros([hidden_layer_size]))\n",
    "    hidden = tf.nn.sigmoid(tf.matmul(inputs, W0) + b0)\n",
    "    W1 = tf.Variable(tf.zeros([hidden_layer_size, num_unique_tokens]))\n",
    "    b1 = tf.Variable(tf.zeros([num_unique_tokens]))\n",
    "    outputs = tf.nn.softmax(tf.matmul(hidden, W1) + b1)\n",
    "    targets = tf.placeholder(tf.float32, [None, num_unique_tokens])\n",
    "    xentropy = -tf.reduce_sum(targets * tf.log(outputs))\n",
    "    \n",
    "    # Initialization\n",
    "    init = tf.initialize_all_variables()\n",
    "    sess.run(init)\n",
    "    \n",
    "    # Training\n",
    "    learning_rate_control = tf.placeholder(tf.float32, [])\n",
    "    train_step = tf.train.GradientDescentOptimizer(\n",
    "        learning_rate * learning_rate_control).minimize(xentropy)\n",
    "    for epoch in xrange(num_epochs):\n",
    "        i = 0\n",
    "        move_to_next_epoch = False\n",
    "        while not move_to_next_epoch:\n",
    "            try:\n",
    "                batch_inputs = np.concatenate(\n",
    "                    [corpus[(i * batch_size) + grams - g:((i + 1) * batch_size) + grams - g]\n",
    "                     for g in xrange(grams)],\n",
    "                    axis=1)\n",
    "                batch_targets = corpus[(i * batch_size) + grams + 1:((i + 1) * batch_size) + grams + 1]\n",
    "                sess.run(train_step, feed_dict={\n",
    "                        inputs: batch_inputs,\n",
    "                        learning_rate_control: 0.25 ** epoch,\n",
    "                        targets: batch_targets})\n",
    "                correct = tf.equal(tf.argmax(outputs, 1), tf.argmax(targets, 1))\n",
    "                accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "                print epoch, i, sess.run(\n",
    "                    accuracy, feed_dict={\n",
    "                        inputs: np.concatenate(\n",
    "                            [corpus[-1001 - g:-1 - g]\n",
    "                             for g in xrange(grams)],\n",
    "                            axis=1),\n",
    "                        targets: corpus[-1000:]})\n",
    "                i += 1\n",
    "            except Exception as e:\n",
    "                if type(e) == KeyboardInterrupt:\n",
    "                    raise(e)\n",
    "                move_to_next_epoch = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
